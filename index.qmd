---
format:
  revealjs:
    pagetitle: "Neural Networks and Randomness"
    footer: "https://2nd-year-milestone-slides.pages.dev/"
    theme: [default, janiths_theme.scss, confirmation_presentation.scss]
    slide-number: true
    smaller: true
    multiplex: true
    history: false
    mermaid:
      theme: neutral
engine: knitr
---


```{r}
library(tidyverse)
library(colorspace)
library(reactable)
library(reactablefmtr)
library(htmltools)
library(here)
library(patchwork)
library(ggbeeswarm)

conflicted::conflicts_prefer(dplyr::filter)

knitr::opts_chunk$set(
  fig.width = 6,
  fig.height = 4,
  fig.align = "center",
  out.width = "100%",
  code.line.numbers = FALSE,
  fig.retina = 4,
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  cache = FALSE,
  dev.args = list(pointsize = 11)
)

options(
  digits = 2,
  width = 60,
  ggplot2.discrete.fill = c("#E57F12", "#38535E"),
  ggplot2.discrete.color = c("#E57F12", "#38535E")
)

theme_set(
  theme_bw(base_size = 14) +
    theme(
      aspect.ratio = 1,
      plot.background = element_rect(fill = 'transparent', colour = NA),
      plot.title.position = "plot",
      plot.title = element_text(size = 24),
      panel.background = element_rect(fill = 'transparent', colour = NA),
      legend.background = element_rect(fill = 'transparent', colour = NA),
      legend.key = element_rect(fill = 'transparent', colour = NA)
    )
)

two_dim_sin <- readr::read_csv(here::here("data/sine-rotated.csv")) |>
  dplyr::rename(class = cl) |>
  dplyr::mutate(class = factor(class), index = row_number())

two_dim_poi <- c(
  617, # B
  722, # A
  800, # B
  684, # A
  400, # A top left corner
  795 # B bottom right corner
)

two_dim_poi_data <- two_dim_sin |>
  filter(index %in% two_dim_poi) |>
  mutate(label = match(index, two_dim_poi))

twod_limes <- readRDS(here::here("data/twod_limes.rds"))
twod_shaps <- readRDS(here::here("data/twod_shaps.rds"))
twod_anchors <- readRDS(here::here("data/twod_anchors.rds"))
twod_cfacts <- readRDS(here::here("data/twod_cfacts.rds"))
```

```{r}
#| echo: false
two_dim_base_plot <- two_dim_sin |>
  ggplot(aes(x = x1, y = x2, color = class)) +
  geom_point(alpha = 0.3) +
  geom_point(data = two_dim_poi_data, size = 2.5, alpha = 1) +
  geom_text(
    data = two_dim_poi_data,
    aes(label = label),
    nudge_x = -0.05,
    nudge_y = -0.05,
    fontface = "bold",
    color = "black"
  ) +
  scale_color_discrete_divergingx(palette = "Zissou 1")
```

```{=html}

<div style="display: flex; flex-direction: row;">
<div style="display: flex; flex-direction: column; justify-content: center; align-items: center; padding: 0 1.5em; max-width: 30vw">
    <img src="imgs/tree-stump.jpg" />
    <span style="font-style: italic; font-size: 0.75rem;">A redwood tree stump, Janith Wanniarachchi 2025</span>
  </div>
  

  <div>

  <h2> Winning the Neural Network Lottery by Chance </h2>
  <span style="display: flex; font-style: italic; font-size: 1.25rem"> How I spent an year trying to fit neural networks with the worse luck imaginable </span>

  <br/>

  <span class = "accent-color" style = "font-family: 'Barlow', sans-serif; font-weight: bold"> Janith Wanniarachchi </span>
  
  <br/>
  
  <span style = "font-style: italic; font-size: 1.5rem; display: block;"> janith.wanniarachchi@monash.edu </span>

  <hr style = "width: 40%; opacity: 0.2; margin-left: 0"/>

  <span style = "font-size: 1.5rem; display: inline-block"> Supervised by Prof. Dianne Cook, Dr. Kate Saunders, Dr. Patricia Menendez, Dr. Thiyanga Talagala </span>

<br/>

</div>

</div>

```

## Let's be honest here {.center}

. . . 

Building a good model is *hard*

. . . 

Explaining how a good model works is even **harder**

::: {.notes}
All right I'll be real with you, i have a hot take that everyone knows but no one wanted to address. Let’s be honest here, building models are hard, we spend enough years in grad school struggling making those but theres a bigger problem here, explaining these models is even harder.
:::

##  {.center .what-if}

. . . 

<img src="imgs/black_box_model-2.png" style = "width: 20%"/>
<br/>
<span style = "font-style: italic; font-size: 1.2rem"> Exhibit A: The good model </span>

. . . 

<div> **What if** you could <br/> poke around and find out <br/> how this model works? </div>

. . . 

**Introducing**

<div class = "accent-color"> **Explainable AI (XAI) methods!** </div>

::: {.notes}
I bring to the court, exhibit A, the black box model which is performing good at the moment and smiling proudly for performing well, (must be nice to be happy like that) but we don’t know how it is making it’s decisions. What if we could poke around and find out how this model works? 
Well there’s a new field that’s being growing in pushing the boundaries of explaining black box models called explainable AI or XAI
:::

## XAI has a lot of facets

XAI can help you look at 

:::: {.columns}

::: {.column width=50%}

<p style = "text-align:center"> <img src="imgs/global_methods_2.png" style="width:90%"/> </p>

How the model reacts to different features overall using <span class="accent-color"> Global Interpretability Methods </span>

:::

::: {.column width=50%}

<p style = "text-align:center"> <img src="imgs/local_methods_2.png" style="width:90%"/> </p>

How the model gives a prediction to one single instance using <span class="accent-color">Local Interpretability Methods </span>

::: 

::::

::: {.notes}
Much like us humans, XAI comes in different varieties, and the two main ones are global and local interpretability methods, since I’ll be talking about bushfires, let’s assume that we have this amazing model that can predict the probability of a bushfire given a future date and location and it’s scarily good. Global methods will tell us how let’s say the temperature affects the chances of bushfire, while local methods will be able to tell us which weather conditions it used to give the prediction for a specific location and time.
:::

## Explaining one prediction

There are several key <span class = "accent-color"> local interpretability methods </span> that are related to each other in how they approach the problem

1. LIME (Local Interpretable Model agnostic Explanations)
2. SHAP (SHapley Additive exPlanations)
2. Anchors
3. Counterfactuals

::: {.notes}
From these two methods generally understanding on a local scale is more informative and there are several methods that are connected together called lime, counterfactuals and anchors.
:::

## But what if, {.center}

<br/>

::: {.fragment .fade-in}

### instead of looking at the numerical values of these XAI methods

:::

<br/>

::: {.fragment .fade-in}

### we represented the numbers as a visual object within the data itself.

:::

## LIME

:::: {.columns}
::: {.column width=60%}

LIME works by trying to find the simplest model within the local neighbourhood that is as similar as possible to the original black box model. Therefore, for a given observation, the LIME explanations are the model coefficients of the interpretable model (e.g. a Generalized Linear Model)

:::
::: {.column width=40%}
```{r}
#| label: fig-2dim-lime
#| fig-width: 6
#| fig-height: 6
#| out-width: 4in
#| out-height: 4in
#| fig-align: "center"
#| fig-cap: "Geometric representation of LIME in two dimensions"
#| echo: false
twod_lime_poi <- twod_limes |>
  group_by(case) |>
  select(
    intercept = model_intercept,
    feature,
    feature_weight,
    yhat = model_prediction
  ) |>
  pivot_wider(names_from = "feature", values_from = "feature_weight") |>
  ungroup() |>
  mutate(
    m = -(x1 / x2),
    case = sort(two_dim_poi),
    chat = (yhat - intercept) / x2
  ) |>
  left_join(
    two_dim_poi_data |> select(x1_data = x1, x2_data = x2, case = index, label)
  ) |>
  mutate(c = x2_data - m * x1_data, match = abs((chat + m * x1_data) - x2_data))

two_dim_base_plot +
  geom_segment(
    data = tibble(
      x1 = two_dim_poi_data$x1 - 0.1,
      x1_end = two_dim_poi_data$x1 + 0.1,
      y = twod_lime_poi$m * x1 + twod_lime_poi$chat,
      y_end = twod_lime_poi$m * x1_end + twod_lime_poi$c,
      label = factor(two_dim_poi_data$label)
    ),
    aes(x = x1, y = y, xend = x1_end, yend = y_end),
    inherit.aes = FALSE,
    show.legend = TRUE
  )
```
:::
::::


## SHAP

:::: {.columns}

::: {.column width=60%}

Similar to LIME, SHAP builds a linear model around the given observation with the features being mapped to a binary vector indicating whether the feature is included in the model or not.

SHAP is based on Shapley values which distributes a reward among cooperative players in a game. In this context the players are the features of the model and the reward is the prediction. 

The coefficients of the model are then given by Shapley values and can be considered as the contribution that the given feature has towards the prediction.

:::
::: {.column width=40%}
```{r fig-2dim-shap}
#| label: fig-2dim-shap
#| fig-width: 6
#| fig-height: 6
#| out-width: 4in
#| out-height: 4in
#| fig-align: "center"
#| fig-cap: "Geometric representation of SHAP in two dimensions."
#| echo: false
two_dim_shap_poi <- twod_shaps$S$A[two_dim_poi, ] |> as.data.frame()
two_dim_base_plot +
  geom_segment(
    data = tibble(
      x1 = two_dim_poi_data$x1,
      x1_end = x1 + two_dim_shap_poi$x1,
      y = two_dim_poi_data$x2,
      y_end = y
    ),
    aes(x = x1, y = y, xend = x1_end, yend = y_end),
    inherit.aes = FALSE,
    arrow = arrow(length = unit(0.1, "cm")),
    lineend = "round",
    linejoin = "bevel",
    show.legend = FALSE
  ) +
  geom_segment(
    data = tibble(
      x1 = two_dim_poi_data$x1,
      x1_end = x1,
      y = two_dim_poi_data$x2,
      y_end = y + two_dim_shap_poi$x2
    ),
    aes(x = x1, y = y, xend = x1_end, yend = y_end),
    inherit.aes = FALSE,
    arrow = arrow(length = unit(0.1, "cm")),
    lineend = "round",
    linejoin = "bevel",
    show.legend = FALSE
  ) +
  scale_color_discrete_divergingx(
    palette = "Zissou 1"
  )
```
:::
::::

## Counterfactuals

:::: {.columns}
::: {.column}

A counterfactual explanation $\boldsymbol{x}_i^{(c)}$ for a given $\boldsymbol{x}_i$ and a desired outcome value $y_{i}^{(\exp)}$, is defined as an observation satisfying the following conditions:

1. $y_{i}^{(\exp)} \approx f(\boldsymbol{x}_i^{(c)})$.
2. $\boldsymbol{x}_i$ and $\boldsymbol{x}_i^{(c)}$ are close to each other in the data space.
3. $\boldsymbol{x}_i^{(c)}$ differs from $\boldsymbol{x}_i$ only in a few components.
4. $\boldsymbol{x}_i^{(c)}$ is a plausible data point according to the distribution of each dimension.
:::
::: {.column}
```{r fig-2dim-cfacts}
#| label: fig-2dim-cfacts
#| echo: false
#| fig-width: 6
#| fig-height: 6
#| out-width: 4in
#| out-height: 4in
#| fig-align: "center"
#| fig-cap: "Geometric representation of Counterfactuals in two dimensions. Hollow diamond shapes represent the counterfactual observations for the observations in solid circles connected through a line."
twod_cfact_poi <- two_dim_poi_data |>
  cbind(twod_cfacts |> rename(x1c = x1, x2c = x2) |> select(x1c, x2c))

two_dim_base_plot +
  geom_segment(
    data = twod_cfact_poi,
    aes(x = x1, y = x2, xend = x1c, yend = x2c)
  ) +
  geom_point(
    data = twod_cfact_poi |>
      mutate(class = ifelse(two_dim_poi_data$class == "A", "B", "A")),
    aes(x = x1c, y = x2c),
    shape = 9,
    size = 2.5,
    alpha = 1
  ) +
  scale_color_discrete_divergingx(
    palette = "Zissou 1"
  )
```
:::
::::

## Anchors

:::: {.columns}
::: {.column}

Anchors are defined as a rule or a set of predicates that satisfy the given instance and is a sufficient condition for $f(x_i)$ with high probability. A predicate is a logical condition that an observation may or may not satisfy.

Finding an anchor for a given instance can be defined as the solution to the following optimization problem,

$$
\max_{\mathcal{A} \text{ s.t. } \text{Pr}(\text{Prec}(\mathcal{A}) \ge \tau) \ge 1 - \delta} \text{Coverage}(\mathcal{A})
$$

The target would then be to maximize the coverage while ensuring that the precision is above a tolerance level.

:::
::: {.column}
```{r fig-2dim-anchors}
#| label: fig-2dim-anchors
#| echo: false
#| fig-width: 6
#| fig-height: 6
#| out-width: 4in
#| out-height: 4in
#| fig-align: "center"
#| fig-cap: "Geometric representation of Anchors in two dimensions"

twod_anchors_poi <- twod_anchors |>
  mutate(
    x1 = case_when(
      is.na(x1) & bound == "lower" ~ min(two_dim_sin$x1),
      is.na(x1) & bound == "upper" ~ max(two_dim_sin$x1),
      TRUE ~ x1
    ),
    x2 = case_when(
      is.na(x2) & bound == "lower" ~ min(two_dim_sin$x2),
      is.na(x2) & bound == "upper" ~ max(two_dim_sin$x2),
      TRUE ~ x2
    )
  )

two_dim_base_plot +
  geom_rect(
    data = cbind(
      twod_anchors_poi |>
        filter(bound == "lower") |>
        rename(xl = x1, yl = x2) |>
        select(xl, yl, id),
      twod_anchors_poi |>
        filter(bound == "upper") |>
        rename(xu = x1, yu = x2) |>
        select(xu, yu)
    ) |>
      mutate(label = two_dim_poi_data$label, class = two_dim_poi_data$class),
    aes(xmin = xl, ymin = yl, xmax = xu, ymax = yu, color = factor(class)),
    inherit.aes = FALSE,
    fill = "transparent",
    linetype = "dashed",
    size = 0.75
  ) +
  scale_color_discrete_divergingx(
    palette = "Zissou 1"
  )
```
:::
::::

## Kultarr R package

```{=html}
<div style="display:flex; flex-direction: row; justify-content: space-around; align-items:center"> 
  <img src="imgs/kultarr-banner.jpg" style="width: 50%"/>
  <img src="imgs/kultarr.svg"/>
</div>
```

:::: {.columns}
::: {.column}
The existing implementations of Anchors were quite hard to work with and were quite slow as it was using an existing Java package. 
:::
::: {.column}
Kultarr is an R package that aims to provide an implementation of Anchors using a simpler algorithm and a complete set of orthogonal predicates. 

Try the package out from [https://github.com/janithwanni/kultarr](https:://github.com/janithwanni/kultarr)
:::
::::

## In two dimensions,

<br/> 

```{=html}
<div style="display:flex; flex-direction: column; justify-content: center; align-items: center; width: 100%; font-size: 2.5rem; font-weight: bold; gap: 2rem">
  <div>
    <span class = "fragment fade-right" data-fragment-index=1>
      <span class = "accent-color">LIME</span> can be seen as
    </span>
    <span class = "fragment fade-left" data-fragment-index=2> 
      <span class = "accent-light-color"> regression lines</span>
    </span>
  </div>
  <div>
    <span class="fragment fade-right" data-fragment-index=4>
      <span class = "accent-color"> SHAP </span> can be seen as
    </span>
    <span class = "fragment fade-left" data-fragment-index=5> 
      <span class = "accent-light-color"> force vectors</span>
    </span>
  </div>
  <div>
    <span class="fragment fade-right" data-fragment-index=6>
      <span class = "accent-color"> Counterfactuals </span> can be seen as
    </span>
    <span class = "fragment fade-left" data-fragment-index=7> 
      <span class = "accent-light-color"> connecting lines</span>
    </span>
  </div>
  <div>
    <span class="fragment fade-right" data-fragment-index=8>
      <span class = "accent-color"> Anchors </span> can be seen as
    </span>
    <span class = "fragment fade-left" data-fragment-index=9> 
      <span class = "accent-light-color"> boxes </span>
    </span>
  </div>
</div>
```

## Further updates to detourr 

:::: {.columns}
::: {.column}
![](imgs/detourr_funcs.gif)
:::
::: {.column}

* Clicking on points in the detourr widget now returns the identifier.
* A proxy was created to communicate with an existing rendered detourr widget.
* Added support for adding points and edges connecting new points.
* Options to customize aesthetics of points and edges.
* Existing points can be highlighted or enlarged.

:::
::::

## Putting it all together {.center}

<div style="display: flex; flex-direction: column; justify-content: center; align-items: center;">
<img src="imgs/app_demo_2.gif" />

</div>

## Rosella R package

```{=html}
<div style="display:flex; flex-direction: row; justify-content: space-around; align-items:center"> 
<img src="imgs/rosella-banner.jpg" style="width:40%" />
  <img src="imgs/rosella.svg" />
</div>
```

:::: {.columns}
::: {.column}
The current status of the XAI explorer was bundled into an R package to ensure that anyone with compute can run the Shiny app on their own servers.
:::
::: {.column}
rosella is an R package that allows you to run the XAI explorer locally on your laptop. It's still under development in terms of allowing users to generate XAI explanations for their own datasets. 

Try the package out from [https://github.com/janithwanni/rosella](https:://github.com/janithwanni/rosella)
:::
::::

# Let's join a cult  

## Being agnostic is fun and all, but {.center}

. . . 

How long has it been since you last spoke to an LLM? 

. . . 

Model Agnostic XAI methods can poke and prod at a model like neural networks but,

. . . 

we want to crack open models to understand the specific internals and possibly simplify them.


# So let's fit a neural network

## Simple stuff first, 

Let's take a look at the following training dataset

```{r}
#| echo: false
library(arrow)
dataset <- arrow::read_parquet(
  "data/train_df_e8c249741a6216445c1edd117488ef326fa93d20.parquet.lz4"
)

original_bound <- jsonlite::fromJSON(
  "[[-10,-10],[-8.875,-3.75],[-4.21875,-3.75],[-0.3125,1.25],[5,-5],[10,10]]"
) |>
  as.data.frame() |>
  setNames(c("x", "y"))

ggplot(dataset, aes(x = x, y = y, color = factor(class))) +
  geom_point(size = 0.5) +
  geom_line(
    data = original_bound,
    aes(x = x, y = y),
    linewidth = 2,
    alpha = 0.5,
    color = "white",
    inherit.aes = FALSE
  ) +
  coord_equal() +
  theme_minimal() +
  labs(color = "Class", x = "x", y = "y")
```

# Quick refresher on how neural networks work

![Playground](https://playground.tensorflow.org/)

## All right for our dataset, {.smaller} 

::::{.columns}
:::{.column .fragment fragment-index=1 width=50%}

#### Fixed hyperparameters (for the plot)

- Number of epochs: 100
- Batch size: 71
- Loss function: Binary Cross Entropy loss
- Optimizer: Adam
- Training set size: 5,000
- Testing set size: 5,000

#### What shall we pick as the number of neurons in a single layer? 

:::
:::{.column .fragment fragment-index=2 width=50%}

![](imgs/mentimeter_qr_code.png){style="width: 4rem; margin: 0 auto; text-align: center; display: block"}

Join the online poll at [menti.com](menti.com) with code `8902 9625` 

<div style='position: relative; padding-bottom: 56.25%; padding-top: 35px; height: 0; overflow: hidden;'><iframe sandbox='allow-scripts allow-same-origin allow-presentation' allowfullscreen='true' allowtransparency='true' frameborder='0' height='315' src='https://www.mentimeter.com/app/presentation/al3izsa4oukki2ynxuqfbv77a219zeb1/embed' style='position: absolute; top: 0; left: 0; width: 100%; height: 100%;' width='420'></iframe></div>

:::
::::

## So based on your results, {.smaller}

This is the result for a single layer neural network with, 

```{r}
#| echo: false

plot_nn_fit <- function(combined, f1_score) {
  data_obj <- arrow::read_parquet(glue::glue(
    "fits/{combined}_fit.parquet.lz4"
  ))
  ggplot(data_obj, aes(x = x, y = y, color = factor(preds))) +
    geom_point(show.legend = F) +
    geom_line(
      data = original_bound,
      aes(x = x, y = y),
      linewidth = 1,
      alpha = 0.5,
      color = "white",
      inherit.aes = FALSE
    ) +
    coord_equal() +
    theme_void() +
    labs(
      title = paste(
        (str_split(combined, "_") |> unlist())[1],
        " neurons"
      )
    )
}

process_metrics <- function(metrics) {
  metrics |>
    bind_rows() |>
    mutate(row_id = row_number()) |>
    pivot_longer(c(f1, acc), names_to = "metric", values_to = "val")
}

rank_metrics <- function() {
  metric_files <- list.files(
    here("metrics"),
    pattern = "*.lz4",
    full.names = TRUE
  )
  metrics <- lapply(metric_files, arrow::read_parquet) |>
    process_metrics()

  metrics |>
    filter(metric == "f1") |>
    group_by(neuron) |>
    arrange(val) |>
    mutate(ranked = row_number()) |>
    ungroup()
}


get_ranked_seed <- function(ranked, neurons, rank_val = 1) {
  x <- ranked |>
    filter(neuron == neurons, ranked == rank_val) |>
    unite(name, neuron, seed, epoch)

  return(list(combined = x$name, val = x$val))
}

ranked <- rank_metrics()
width <- 1080
height <- 1080

if (!file.exists(here("imgs/nn_fits.gif"))) {
  fname_ls <- lapply(unique(ranked$ranked), function(r) {
    print(r)
    a <- list(
      four = get_ranked_seed(ranked, 4, rank_val = r),
      eight = get_ranked_seed(ranked, 8, rank_val = r),
      five = get_ranked_seed(ranked, 5, rank_val = r),
      ten = get_ranked_seed(ranked, 10, rank_val = r),
      twenty = get_ranked_seed(ranked, 20, rank_val = r),
      thirty = get_ranked_seed(ranked, 30, rank_val = r)
    )
    p <- plot_nn_fit(a$four$combined, a$four$val) +
      plot_nn_fit(a$eight$combined, a$eight$val) +
      plot_nn_fit(a$five$combined, a$five$val) +
      plot_nn_fit(a$ten$combined, a$ten$val) +
      plot_nn_fit(a$twenty$combined, a$twenty$val) +
      plot_nn_fit(a$thirty$combined, a$thirty$val)

    fname <- glue::glue("nn_fits/{r}_rank.png")
    ggsave(
      plot = p,
      filename = fname,
      width = width,
      height = height,
      units = "px",
      bg = "white",
      device = "png"
    )
    return(fname)
  })

  gifski(
    png_files = unlist(fname_ls),
    gif_file = here("imgs/nn_fits.gif"),
    delay = 0.1,
    width = width,
    height = height
  )
}
```

::::{.columns}
:::{.column width=80%}
```{r}
#| echo: false
#| fig-label: nn_fit_holder

a <- list(
  four = get_ranked_seed(ranked, 4),
  eight = get_ranked_seed(ranked, 8),
  five = get_ranked_seed(ranked, 5),
  ten = get_ranked_seed(ranked, 10),
  twenty = get_ranked_seed(ranked, 20),
  thirty = get_ranked_seed(ranked, 30)
)
plot_nn_fit(a$four$combined, a$four$val) +
  plot_nn_fit(a$eight$combined, a$eight$val) +
  plot_nn_fit(a$five$combined, a$five$val) +
  plot_nn_fit(a$ten$combined, a$ten$val) +
  plot_nn_fit(a$twenty$combined, a$twenty$val) +
  plot_nn_fit(a$thirty$combined, a$thirty$val)
```
:::
:::{.column .fragment .fade-in width=20%}
Are we sure though?
```{=html}
<style> button:hover { transform: none; } </style>
<script>const fnclk = function() { 
document.querySelector("div[data-fig-label='nn_fit_holder'] img").src = "imgs/nn_fits.gif"
document.querySelector("div[data-fig-label='nn_fit_holder'] img").style = "width: 65%"
}</script>
<button onclick="fnclk()" style="border-radius: 5px; padding: 0.5em; border: 1px solid lightgray; background-color: silver; color: black"> Check again </button>
```

:::
::::

## Wait, Hol' up

:::{.panel-tabset}

### Worst of each {.smaller}

:::{style = "width: 50vw"}
```{r}
#| echo: false

a <- list(
  four = get_ranked_seed(ranked, 4),
  eight = get_ranked_seed(ranked, 8),
  five = get_ranked_seed(ranked, 5),
  ten = get_ranked_seed(ranked, 10),
  twenty = get_ranked_seed(ranked, 20),
  thirty = get_ranked_seed(ranked, 30)
)
plot_nn_fit(a$four$combined, a$four$val) +
  plot_nn_fit(a$five$combined, a$five$val) +
  plot_nn_fit(a$eight$combined, a$eight$val) +
  plot_nn_fit(a$ten$combined, a$ten$val) +
  plot_nn_fit(a$twenty$combined, a$twenty$val) +
  plot_nn_fit(a$thirty$combined, a$thirty$val)
```
:::

### Best of each

:::{style = "width: 50vw"}
```{r}
#| echo: false

a <- list(
  four = get_ranked_seed(ranked, 4, rank_val = 400),
  eight = get_ranked_seed(ranked, 8, rank_val = 400),
  five = get_ranked_seed(ranked, 5, rank_val = 400),
  ten = get_ranked_seed(ranked, 10, rank_val = 400),
  twenty = get_ranked_seed(ranked, 20, rank_val = 400),
  thirty = get_ranked_seed(ranked, 30, rank_val = 400)
)
plot_nn_fit(a$four$combined, a$four$val) +
  plot_nn_fit(a$five$combined, a$five$val) +
  plot_nn_fit(a$eight$combined, a$eight$val) +
  plot_nn_fit(a$ten$combined, a$ten$val) +
  plot_nn_fit(a$twenty$combined, a$twenty$val) +
  plot_nn_fit(a$thirty$combined, a$thirty$val)
```
:::

### Spread of model metrics

:::{style = "width: 60vw"}
```{r}
#| echo: false
metric_files <- list.files(
  here("metrics"),
  pattern = "*.lz4",
  full.names = TRUE
)
metrics <- lapply(metric_files, arrow::read_parquet) |>
  process_metrics()

spreads <- metrics |>
  group_by(neuron) |>
  arrange(val) |>
  mutate(ranked = row_number()) |>
  ungroup()

ggplot(
  data = spreads |>
    mutate(
      metric = case_when(
        metric == "f1" ~ "F1 Score",
        metric == "acc" ~ "Accuracy"
      )
    ),
  aes(y = fct_rev(as.factor(neuron)), x = val, color = metric)
) +
  geom_quasirandom(size = 0.1) +
  facet_wrap(~metric) +
  theme_minimal() +
  labs(color = "Metric type", y = "Number of neurons", x = "Metric value")
```
:::


:::

# Any guesses on what exactly happened here?

## For an entire year I used the wrong seed

The random seed has an effect on how neural networks are being built.

:::{.fragment .fade-in}

But why does the seed have an effect? 

:::{.incremental}

- It can be due to primarily the initial weights used in the training, which has been discussed in the lottery ticket hypothesis Model Agnostic Meta Learning (MAML), and many more cases.
- It can be due to shuffling in mini batches. 
:::

:::

# Cool story mate, so what?

## Smaller models for small datasets 

I could have chucked a 20 neuron two hidden layer neural network with 500 epochs, 

:::{.fragment .fade-in}

But for this dataset? Does this decision boundary demand a model with more parameters than there are bends in the decision boundary?

:::{style = "width: 40vw; margin: 0 auto; display: block"}
```{r}
#| echo: false

ggplot(dataset, aes(x = x, y = y, color = factor(class))) +
  geom_point(size = 0.5) +
  geom_line(
    data = original_bound,
    aes(x = x, y = y),
    linewidth = 2,
    alpha = 0.5,
    color = "white",
    inherit.aes = FALSE
  ) +
  coord_equal() +
  theme_minimal() +
  labs(color = "Class", x = "x", y = "y")
```
:::

:::

## Fixing things before it starts {.center}

<br/>

:::{.fragment fragment-index=1}
In a majority of deep learning education material very rarely is the effect of the random seed discussed.

<br/>

That is why I built a tool for data science educators to educate students by trying out multiple model variants and seeing the difference
:::

:::{.fragment fragment-index=2}
#### And today you get to try that out as well
:::

:::{.fragment fragment-index=3}
#### As the second batch of students to experience the app
:::

## Introducing The Blind Box Simulator {.center}

Visit [random-nn-playground.janith.com](http://random-nn-playground.janith.com)

## The architecture behind the app

```{mermaid}
graph TB
    
    %% Main Application Layer
    subgraph "Main Application (R/Shiny)"
        %% Frontend Layer
        subgraph "Frontend Layer"
            UI[Fomantic UI Components]
            Squiggler[Squiggler Tool<br/>Svelte → JS/CSS]
        end

        Shiny[Shiny Web Framework<br/>Rhino for<br/>Codebase Management]
        
        %% Visualization Components
        subgraph "Visualization Libraries"
            GGPlot[ggplot2<br/>Static Plots]
            Beeswarm[ggbeeswarm<br/>Plot Geometry]
            Ggiraph[ggiraph<br/>Interactivity]
            Gifski[gifski<br/>GIF Animations<br/>Rust-powered]
        end

        %% Backend Processing Layer
        subgraph "Backend Processing"
            Python[Python Background Tasks<br/>Model Fitting<br/>with PyTorch<br/>]
            Parquet[Parquet Files<br/>for Data Transfer]
        end

    end
    
    
    %% Data Layer
    %% subgraph "Data Storage"
    %% end
    
    %% Connections
    UI --> Shiny
    Squiggler --> Shiny
    
    %% Visualization connections
    Shiny --> GGPlot
    Shiny --> Beeswarm
    Shiny --> Ggiraph
    Shiny --> Gifski
    
    %% Interactive plot creation
    Beeswarm --> Ggiraph
    
    %% Backend connections
    Shiny -.->|Background Task| Python
    Python --> Parquet
    Shiny --> Parquet
    
    %% Styling
    classDef frontend fill:#e1f5fe
    classDef rshiny fill:#f3e5f5
    classDef backend fill:#fff3e0
    classDef data fill:#e8f5e8
    
    class UI,Squiggler frontend
    class Shiny,GGPlot,Beeswarm,Ggiraph,Gifski rshiny
    class Python,PyTorch backend
    class Parquet data
```


## The methodology behind the app

:::{style = "width: 80vw; margin: 0 auto; display: block"}
```{mermaid}
flowchart TB
    A["Start: Input Decision Boundary Function f<br/>Seed Range [1, 99999]<br/> Neuron Sizes N"] --> P1
    
    subgraph P1 ["Phase 1: Dataset Generation"]
        direction LR
        B[Set Consistent Seed for Reproducibility]
        C["Generate 10,000 Samples<br/>Uniformly from [-10, 10] × [-10, 10]"]
        
        B --> C
    end
    
    P1 --> P2
    
    subgraph P2 ["Phase 2: Parallel Training Process"]
        direction LR
        G[For Each Neuron Size n ∈ N]
        H["Select Random Seed s ∈ [1, 99999]"]
        I["Initialize Neural Network:<br/>Input: 2, Hidden: n (ReLU), Output: 1 (Sigmoid)"]
        J[Configure: Batch=71, Adam lr=0.01, BCE Loss]
        
        K[Training Loop: 500 Epochs]
        L[Shuffle Data → Batch Processing]
        M[Forward Pass → Loss → Backward Pass]
         
        G --> H --> I --> J --> K
        K --> L --> M
    end
    
    P2 --> P3
    
    subgraph P3 ["Phase 3: Model Evaluation"]
        direction LR
        P[For Each Trained Model M]
        Q[Evaluate on Testing Dataset:<br/>• Compute Predictions<br/>• Calculate F1-Score & Accuracy]
        R[Create Decision Boundary:<br/>• Generate 100×100 Grid<br/>• Apply Model to Grid]
        T[Return: Models, Metrics, Boundaries]
        
        P --> Q --> R --> T 
    end
    
    P3 --> U[End]
```
:::

# Attention is all you need, but did we need this much attention? {.smaller}

## What we are planning on doing?

::::{.columns}
:::{.column width=50%}

Using a simple toy transformer model trained to solve problems of the form `5 + 7 % 10 = ?`.

![Toy Transformer Models](imgs/basic_schematic.png){width=80%}
:::
:::{.column width=50%}

Visualise how the attention heads learn by using Sparse Auto Encoders

![Training Dynamics in Toy Models of Superimposition](imgs/tmos-img.png){width=80%}
:::
::::

# Looking back and forward

## Thesis Structure

:::{style = "width: 60vw; margin: 0 auto; display: block"}
```{mermaid}
mindmap
  root((The thesis))
    How can traditional machine learning models be explained visually?
      Kultarr: A simple, visual rewrite of Kultarr
        Geometric representations of XAI
          Rosella: An XAI explorer
    What are the hurdles to explain deep learning models?
      Complex models over parsimonious models
        The effect of random numbers used in the model
    How can we make a dent in understanding large language models?
      Visualizing trajectory of weights over time 
      Identifying circuits between attention heads
```

:::

# Timeline

:::{style = "width: 60vw; margin: 0 auto; display: block"}

```{r}
#| label: fig-timeline
#| fig-cap: "Project timeline for the PhD"
#| fig-width: 11
#| echo: false

year_one <- tribble(
  ~activity,
  ~start_date,
  ~end_date,
  "Completing coursework",
  1,
  5,
  "Completing coursework",
  8,
  12,
  "Reproducing Anchors as the kultarr package",
  1,
  3,
  "Working paper on the visualisation of anchors",
  7,
  8,
  "Developing improvements to detourr",
  8,
  10,
  "Developing methods to visualise XAI methods with detourr",
  9,
  12,
  "Working paper on geometric representations of XAI",
  11,
  13
) |>
  mutate(wp = "Year one")

# start from 13
year_two <- tribble(
  ~activity,
  ~start_date,
  ~end_date,
  "Developing dataset generators for robustness testing of XAI",
  1,
  2,
  "Developing dataset generators for robustness testing of XAI",
  1,
  2,
  "Bundling XAI Explorer into an R package",
  8,
  12,
  "Testing disagreements between SHAP and Counterfactuals",
  1,
  3,
  "Testing effect of density on neural network model fit",
  7,
  8,
  "Investigating the effect of the seed on the model",
  1,
  1,
  "Building the POC tool",
  1,
  1
) |>
  mutate(
    wp = "Year two",
    start_date = start_date + 13,
    end_date = end_date + 13
  )

year_three <- tribble(
  ~activity,
  ~start_date,
  ~end_date,
  "Preparing to submit the first year paper",
  1,
  2,
  "Writing up paper for the second year project",
  1,
  3,
  "Work on toy transformer models",
  2,
  6,
  "Writing up paper on visualisation of circuits",
  4,
  6,
  "Thesis writing",
  6,
  12
) |>
  mutate(
    wp = "Year three",
    start_date = start_date + 24,
    end_date = end_date + 24
  )


prj_data <- bind_rows(
  list(year_one, year_two, year_three)
)

ganttrify::ganttrify(
  project = prj_data |> select(wp, activity, start_date, end_date),
  project_start_date = "2023-07",
  size_text_relative = 1.5,
  month_breaks = 6,
  colour_palette = wesanderson::wes_palette("Zissou1")[1]
) +
  labs(title = "PhD timeline")
```

:::


## Thank you! {.center}

Have any suggestions or ideas? {{< fa comment >}}

```{=html}
<div class = "card-container">
  <div class="card">
    <div class="card-text">
      <div class="portada">
        <img src = "imgs/banner_img_1.jpg" />
        <span style="font-size: 0.7rem; font-style: italic;"> The colour palette for these slides are inspired by the photograph by Bill Henson as part of the art installation Oneiroi in the Hellenic Museum, Melbourne. </span>
      </div>
      <div class="title-total"> 
        <div class = "img-container">
          <div class = "img-avatar">
            <img src = "imgs/profile_picture.jpeg "/>
          </div>
        </div>
        <h4 class="accent-color">Janith Wanniarachchi</h4>
        <div class="desc">
          <div>
            <span> <i class="fa-regular fa-envelope fa-sm"></i> </span> 
            <span class = "contact-detail"> janith.wanniarachchi@monash.edu </span>
          </div>
          <div>
            <span> <i class="fa-brands fa-github-alt fa-sm"></i> </span>
            <span class = "contact-detail"> @janithwanni </span>
          </div>
          <div>
            <span> <i class = "fa-brands fa-linkedin"></i></span>
            <span class = "contact-detail"> janith-wanniarachchi </span>
          </div>
          <div>
            <span> <i class = "fa-solid fa-globe fa-sm"></i> </span>
            <span class = "contact-detail"> janithwanni.netlify.app </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
```

